{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Note 5**: Hyperparameter optimization\n",
    "<br><br>\n",
    "Hyperparameters are parameters that are set before the learning process started. They control the algorithm responsible to optimize the objective function and directly influence how well the model performs. Tuning those hyperparameters (which defer depending on the model) manually is a very long and painful process. Thankfully there are other ways to improve their values which don't require more work for engineers. \n",
    "<br><br>\n",
    "\n",
    "#### 1. Grid search\n",
    "Considered the traditional way to optimize hyperparameters. Also called a brute-force search or an exhaustive search, it consists in choosing a set of values for each hyperparameter to optimize and try all combinations before to select the one which performs best using K-fold cross-validation. This technic suffers from the curse of dimensionality and wastes a lot of time analyzing bad hyperparameters because of its uninformed nature. \n",
    "<br>image source: https://goo.gl/8JJECg\n",
    "<br><br>\n",
    "![title](ims/gridsearch.jpg)\n",
    "\n",
    "<br><br>\n",
    "#### 2. Random search\n",
    "Randomly sets values over a search space using a specified probability distribution. This technic has proven to be better than grid search especially for low intrinsic dimensionality problems where few hyperparameters influence the algorithm. It does not guarantee to find any good parameters by its random and uninformed nature.\n",
    "<br>image source:: https://goo.gl/8JJECg\n",
    "<br><br>\n",
    "![title](ims/randomsearch.jpg)\n",
    "<br><br>\n",
    "#### 3. Bayesian search\n",
    "Combines values exploration and exploitation. A probabilistic model based on Bayesian optimization is used to try new values and focus on the most promising one. Bayesian optimization uses a Gaussian Process function to predict posterior function based on prior function and an acquisition function to determine the next sampling point. It beats previous methods as it is capable of selecting hyperparameter values based on previous analysis.\n",
    "<br>image source: https://goo.gl/ZYEdt8\n",
    "<br><br>\n",
    "![title](ims/bayesian.png)\n",
    "<br><br>\n",
    "Other methods also exist such as Gradient-based optimization, evolutionary optimization, and population-based optimization. I did not investigate them yet.The architecture of the model can also be optimized using those technics. In the next part of the notebook, I experimented with two libraries called **Hyperas and Talos**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Hyperas \n",
    "https://github.com/maxpumperla/hyperas\n",
    "\n",
    "\n",
    "<br>\n",
    "I tested the library on a toy dataset I created in a previous notebook. I only added a function to generate and save it to .npy Binary files so I can load the exact same dataset through the different model evaluations (**data.py**). I also reused the model but modify it to be used with hyperas (**hyperas.py**). After 25 trials, the best model output a loss value of 1.107572268210788e-07 and a perfect accuracy on the test set. Note that hyperas should run using the command line and free of comments.\n",
    "\n",
    "<br>\n",
    "The best model used the following hyperparamter values:\n",
    "<br><br>\n",
    "{'Activation': 0, 'Activation_1': 1, 'Dense': 2, 'Dense_1': 2, 'Dropout': 0.031459480186175934, 'batch_size': 0, 'lr': 0.0054328707426503095}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    '''Load the dataset\n",
    "    '''\n",
    "    path = 'D:/DATA/Works/AI/100_Posts/hyperparameter-tunning/data'\n",
    "    x_train = np.load(os.path.join(path,'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(path,'y_train.npy'))\n",
    "    x_test = np.load(os.path.join(path,'x_test.npy'))\n",
    "    y_test = np.load(os.path.join(path,'y_test.npy'))\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    '''Create the model with hyperas functions\n",
    "    '''\n",
    "    Inputs = (64, 64, 3)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(KL.Conv2D(32, kernel_size=(3, 3),input_shape=Inputs))\n",
    "    model.add(KL.Activation('relu'))\n",
    "    model.add(KL.BatchNormalization())\n",
    "    model.add(KL.MaxPooling2D((2, 2)))\n",
    "    model.add(KL.Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    model.add(KL.Flatten())\n",
    "    model.add(KL.Dense({{choice([16 ,32, 64, 128])}}))\n",
    "    model.add(KL.Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "\n",
    "\n",
    "    if {{choice(['three', 'four'])}} == 'four':\n",
    "        model.add(KL.Dense({{choice([16 ,32, 64, 128])}}))\n",
    "        model.add(KL.Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(KL.Dense(1))\n",
    "    model.add(KL.Activation('sigmoid'))\n",
    "\n",
    "\n",
    "    adam=Adam(lr={{uniform(0.00005,0.01)}})\n",
    "    model.compile(optimizer=adam,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[metrics.binary_accuracy])\n",
    "\n",
    "\n",
    "    H = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=6,\n",
    "        batch_size={{choice([64, 128])}})\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                              data=data,\n",
    "                                              algo=tpe.suggest,\n",
    "                                              max_evals=25,\n",
    "                                              trials=Trials())\n",
    "\n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = data()\n",
    "    print(\"Evalutation of best performing model:\")\n",
    "    print(best_model.evaluate(X_test, Y_test))\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Talos\n",
    "https://github.com/autonomio/talos\n",
    "\n",
    "<br>\n",
    "Talos is another tool that I tried this week. Instead of setting possible values in the model architecture like hyperas, it passes them as a dictionary of parameters which is more readable. I got pretty similar results with the previous library but found the overall experience more delightful with many powerful helper functions to analyze results. (**talos_optim.py**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    '''Load the dataset\n",
    "    '''\n",
    "    path = 'D:/DATA/Works/AI/100_Posts/hyperparameter-tunning/data'\n",
    "    x_train = np.load(os.path.join(path,'x_train.npy'))\n",
    "    y_train = np.load(os.path.join(path,'y_train.npy'))\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def create_model(x_train, y_train, x_val, y_val, params):\n",
    "    '''Create the model with talos functions\n",
    "    '''\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(KL.Conv2D(32, kernel_size=(3, 3),input_shape=(64, 64, 3)))\n",
    "    model.add(KL.Activation('relu'))\n",
    "    model.add(KL.BatchNormalization())\n",
    "    model.add(KL.MaxPooling2D((2, 2)))\n",
    "    model.add(KL.Dropout(params['dropout']))\n",
    "\n",
    "    model.add(KL.Flatten())\n",
    "    model.add(KL.Dense(params['first_neuron']))\n",
    "    model.add(KL.Activation(params['activation']))\n",
    "\n",
    "    model.add(KL.Dense(1))\n",
    "    model.add(KL.Activation('sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=params['optimizer'](),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=[metrics.binary_accuracy])\n",
    "\n",
    "\n",
    "    H = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        validation_data=[x_val, y_val],\n",
    "        epochs=params['epochs'],\n",
    "        batch_size=params['batch_size'])\n",
    "\n",
    "    return H, model\n",
    "\n",
    "\n",
    "\n",
    "x, y = data()\n",
    "\n",
    "p = {'dropout': [0,0.25,0.5,0.75],\n",
    "    'first_neuron':[16 ,32, 64, 128, 256],\n",
    "    'activation':[relu, elu],\n",
    "    'optimizer': [Nadam, Adam],\n",
    "    'epochs': [6],\n",
    "    'batch_size': [32, 64]}\n",
    "\n",
    "\n",
    "t = ta.Scan(x=x,\n",
    "            y=y,\n",
    "            model=create_model,\n",
    "            params=p,\n",
    "            dataset_name='shapes',\n",
    "            grid_downsample=1,\n",
    "            experiment_no='1')\n",
    "\n",
    "\n",
    "result = to.main()\n",
    "result.high('val_binary_accuracy')\n",
    "result.best_params('val_binary_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Finally\n",
    "To know how much hyperparameter optimization is worth, it is necessary to compare its result with a non-optimized model. To do so, I trained the exact same model with generic values on the same number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.9013 - binary_accuracy: 0.5600\n",
      "Epoch 2/6\n",
      "100/100 [==============================] - 0s 220us/step - loss: 0.4585 - binary_accuracy: 0.9300\n",
      "Epoch 3/6\n",
      "100/100 [==============================] - 0s 221us/step - loss: 0.3096 - binary_accuracy: 0.9300\n",
      "Epoch 4/6\n",
      "100/100 [==============================] - 0s 221us/step - loss: 0.0703 - binary_accuracy: 0.9800\n",
      "Epoch 5/6\n",
      "100/100 [==============================] - 0s 231us/step - loss: 0.0265 - binary_accuracy: 0.9900\n",
      "Epoch 6/6\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0147 - binary_accuracy: 0.9900\n",
      "50/50 [==============================] - 0s 2ms/step\n",
      "loss and binary accuracy on test samples [0.06147673666477203, 0.9600000023841858]\n"
     ]
    }
   ],
   "source": [
    "#For the notebook's clarity, the code is moved the script called no_optim\n",
    "import no_optim as no\n",
    "\n",
    "no.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Note:\n",
    "1. Overall the hyperparameter optimization performs better than the non-optimized model on the test set after 6 epochs (accuracy is not a perfect metrics, TODO: should monitor with the ROC AUC or Precision- Recall metrics). However, the task to solve here is rather easy so a bigger amount of epochs both would be similar for optimized or not models. However I tried it on a real project with a more complicated task and it really impacted the learning phase, especially the time used by the network to reach its local minima.\n",
    "<br><br>\n",
    "\n",
    "2. I experimented with two libraries called hyperas (hyperopt's wrapper) and talos. I aim to study not only deep learning but also a wider set of machine learning models in the next few weeks. Therefore, I will focus on hyperopt for its wider compatibility. https://goo.gl/pWW7JJ \n",
    "<br><br>\n",
    "\n",
    "3. I did not uncover yet all features and possibilities of the two libraries but aim to investigate it during the current and future projects' development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Resources:\n",
    "*** Wikipedia** - Hyperparameter optimization https://goo.gl/tUSCFh\n",
    "<br><br>\n",
    "*** Prabhu** - Understanding Hyperparameters and its Optimisation techniques https://goo.gl/RjVGGt\n",
    "<br><br>\n",
    "*** Will Koehrsen** - Automated Machine Learning Hyperparameter Tuning in Python https://goo.gl/3P184e\n",
    "<br><br>\n",
    "*** Will Koehrsen** - A Conceptual Explanation of Bayesian Hyperparameter Optimization for Machine Learning https://goo.gl/DcAuQp\n",
    "<br><br>\n",
    "**Siraj Raval** Hyperparameter Optimization - The Math of Intelligence #7 https://www.youtube.com/watch?v=ttE0F7fghfk\n",
    "<br><br>\n",
    "*** Hvass Laboratories** - TensorFlow Tutorial #19 Hyper-Parameter Optimization https://goo.gl/bxcdZc\n",
    "<br><br>\n",
    "*** James Bergstra, Remi Bardenet, Yoshua Bengio, Balazs Kegl** Algorithms for Hyper-Parameter Optimization https://goo.gl/dTCyBG\n",
    "<br><br>\n",
    "*** James Bergstra, Yoshua Bengio** Random Search for Hyper-Parameter Optimization https://goo.gl/eKcLjL\n",
    "<br><br>\n",
    "*** J. Bergstra, D. Yamins, D. D. Cox** Making a Science of Model Search: Hyperparameter Optimization\n",
    "in Hundreds of Dimensions for Vision Architectures https://goo.gl/AUKwa4\n",
    "<br><br>\n",
    "*** Jasper Snoek, Hugo Larochelle, Ryan P. Adams** Practical Bayesian Optimization of Machine Learning Algorithms https://goo.gl/jLYPCj\n",
    "<br><br>\n",
    "*** Ian Dewancker, Michael McCourt, Scott Clark** Bayesian Optimization Primer https://goo.gl/YZNAVv\n",
    "<br><br>\n",
    "*** Jan N. van Rijn and Frank Hutter** An Empirical Study of Hyperparameter Importance Across Datasets https://goo.gl/9tJRn4\n",
    "<br><br>\n",
    "*** Jason Brownlee** How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras https://goo.gl/rnDtrW\n",
    "<br><br>\n",
    "*** Kishan Maladkar** Why Is Random Search Better Than Grid Search For Machine Learning https://goo.gl/TMKpq3\n",
    "<br><br>\n",
    "*** Miko** Hyperparameter Optimization with Keras https://goo.gl/373LbF https://github.com/autonomio/talos\n",
    "<br><br>\n",
    "**Tensorflow 2.0** What's new in TensorBoard (TF Dev Summit '19) https://goo.gl/RLBCXT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
